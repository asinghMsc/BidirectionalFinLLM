# BidirectionalFinLLM

Analysing the length distribution shows that a block size of 25 would be sufficient but 32 is ideal for a little buffer. IF prompt/target lengths grow in the future, will need headroom.

[x] Analyse lengths and Hyperparameters <br>
[x] Prep data for both directions<br>
[x] Attention mechanisms<br>
[ ] FeedFoward and TransformerBlock<br>
[ ] Main model<br>
[ ] Data loader<br>
[ ] Training Loop<br>
