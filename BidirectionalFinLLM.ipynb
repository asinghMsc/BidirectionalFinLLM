{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N8g2tVFC6go7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import tiktoken\n",
        "\n",
        "#special token ids\n",
        "enc = tiktoken.get_encoding('cl100k_base')\n",
        "SOS_TOKEN_ID = enc.encode(\"<|startoftext|>\", allowed_special=\"all\")[0]\n",
        "EOS_TOKEN_ID = enc.encode(\"<|endoftext|>\", allowed_special=\"all\")[0]\n",
        "PAD_TOKEN_ID = 0\n",
        "\n",
        "# HP\n",
        "batch_size = 32\n",
        "block_size = 32\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "vocab_size = 100_000\n",
        "n_embed = 256\n",
        "n_layers = 4\n",
        "learning_rate = 1e-3\n",
        "max_iters = 10000\n",
        "eval_interval = 100\n",
        "n_heads = 4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CPVJVQirKKIL"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/sample_data/financial_narration_data.csv\")\n",
        "\n",
        "# functions prep pairs each way,  process df into tokenised id tuples\n",
        "\n",
        "#json to str\n",
        "json_to_str_dataset = []\n",
        "for _, row in df.iterrows():\n",
        "  encoder_input_ids = enc.encode(row['prompt'])\n",
        "  decoder_target_ids = enc.encode(row['target']) + [EOS_TOKEN_ID]\n",
        "  decoder_input_ids = [SOS_TOKEN_ID] + decoder_target_ids[:-1]\n",
        "  json_to_str_dataset.append((encoder_input_ids, decoder_input_ids, decoder_target_ids))\n",
        "\n",
        "#str to json\n",
        "str_to_json_dataset = []\n",
        "for _, row in df.iterrows():\n",
        "  encoder_input_ids = enc.encode(row['target'])\n",
        "  decoder_target_ids = enc.encode(row['prompt']) + [EOS_TOKEN_ID]\n",
        "  decoder_input_ids = [SOS_TOKEN_ID] + decoder_target_ids[:-1]\n",
        "  str_to_json_dataset.append((encoder_input_ids, decoder_input_ids, decoder_target_ids))\n",
        "\n",
        "#split\n",
        "n_j2s = int(0.9 * len(json_to_str_dataset))\n",
        "train_json_to_str = json_to_str_dataset[:n_j2s]\n",
        "val_json_to_str = json_to_str_dataset[n_j2s:]\n",
        "\n",
        "n_s2j = int(0.9 * len(str_to_json_dataset))\n",
        "train_str_to_json = str_to_json_dataset[:n_s2j]\n",
        "val_str_to_json = str_to_json_dataset[n_s2j:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8DgITDPwRQlo"
      },
      "outputs": [],
      "source": [
        "# general attention head\n",
        "class AttentionHead(nn.Module):\n",
        "  def __init__(self, n_embed, head_size):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "    self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "    self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    self.head_size = head_size\n",
        "\n",
        "  # takes separate q_input, k_input and v_input (correct for a generic head)\n",
        "  def forward(self, query_input, key_input, value_input, mask=None):\n",
        "    q = self.query(query_input)\n",
        "    k = self.key(key_input)\n",
        "    v = self.value(value_input)\n",
        "\n",
        "    wei = q @ k.transpose(-2, -1) * (self.head_size**-0.5)\n",
        "\n",
        "    if mask is not None:\n",
        "      wei = wei.masked_fill(mask == 0, float('-inf'))\n",
        "    wei = F.softmax(wei, dim=-1)\n",
        "    wei = self.dropout(wei)\n",
        "    out = wei @ v\n",
        "    print(f\"Shape of out from AttentionHead.forward (before return): {out.shape}\")\n",
        "    return out\n",
        "\n",
        "# multi-head attention, for selfattention with a causal flag\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, n_embed, n_heads, block_size, is_causal):\n",
        "    super().__init__()\n",
        "    self.n_heads = n_heads\n",
        "    self.head_size = n_embed // n_heads\n",
        "\n",
        "    self.heads = nn.ModuleList([\n",
        "        AttentionHead(n_embed, self.head_size) for _ in range(n_heads)\n",
        "    ])\n",
        "    self.proj = nn.Linear(n_heads * self.head_size, n_embed)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    self.is_causal = is_causal\n",
        "\n",
        "    if self.is_causal:\n",
        "      self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "  def forward(self, x, mask=None):\n",
        "    B, T, C = x.shape\n",
        "    local_mask = mask\n",
        "\n",
        "    if self.is_causal:\n",
        "      casual_mask = self.tril[:T, :T].to(x.device)\n",
        "      if local_mask is None:\n",
        "        local_mask = casual_mask\n",
        "      else:\n",
        "        if local_mask.ndim == 3:\n",
        "            local_mask = local_mask.unsqueeze(1) #reshape to (B, 1, T, T)\n",
        "        local_mask = local_mask * casual_mask\n",
        "\n",
        "    # Pass the combined mask to the attention heads\n",
        "    out = torch.cat([h(x, x, x, mask=local_mask) for h in self.heads], dim=-1)\n",
        "    out = self.dropout(self.proj(out))\n",
        "    return out\n",
        "\n",
        "# MHCA for encoder-decoder attention\n",
        "class MultiHeadCrossAttention(nn.Module):\n",
        "  def __init__(self, n_heads, n_embed, head_size):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([\n",
        "        AttentionHead(n_embed, head_size) for _ in range(n_heads)\n",
        "    ])\n",
        "    self.proj = nn.Linear(n_heads * head_size, n_embed)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "  def forward(self, query_input, key_value_input, mask=None):\n",
        "    local_mask = mask\n",
        "    if local_mask is not None:\n",
        "        # ensure mask has the correct shape for broadcasting with attention weights (B, H, T_q, T_k)\n",
        "        if local_mask.ndim == 3:\n",
        "            local_mask = local_mask.unsqueeze(1) #reshape to (B, 1, T_q, T_k)\n",
        "\n",
        "    out = torch.cat([h(query_input, key_value_input, key_value_input, mask=local_mask) for h in self.heads], dim=-1)\n",
        "    out = self.dropout(self.proj(out))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4ssTntZrqhpi"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, n_embed):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(n_embed, 4 * n_embed),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4 * n_embed, n_embed),\n",
        "        nn.Dropout(0.1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "      return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jNqIs7slq8r3"
      },
      "outputs": [],
      "source": [
        "# general attention head\n",
        "class AttentionHead(nn.Module):\n",
        "  def __init__(self, n_embed, head_size):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "    self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "    self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    self.head_size = head_size\n",
        "\n",
        "  # takes separate q_input, k_input and v_input (correct for a generic head)\n",
        "  def forward(self, query_input, key_input, value_input, mask=None):\n",
        "    print(f\"AttentionHead - query_input shape: {query_input.shape}\")\n",
        "    print(f\"AttentionHead - key_input shape: {key_input.shape}\")\n",
        "    print(f\"AttentionHead - value_input shape: {value_input.shape}\")\n",
        "\n",
        "    q = self.query(query_input) # (B, T_q, head_size)\n",
        "    k = self.key(key_input)     # (B, T_k, head_size)\n",
        "    v = self.value(value_input)   # (B, T_v, head_size)\n",
        "\n",
        "    print(f\"AttentionHead - q shape: {q.shape}\")\n",
        "    print(f\"AttentionHead - k shape: {k.shape}\")\n",
        "    print(f\"AttentionHead - v shape: {v.shape}\")\n",
        "\n",
        "    # compute attention scores (weights)\n",
        "    # (B, T_q, head_size) @ (B, head_size, T_k) -> (B, T_q, T_k)\n",
        "    k_transposed = k.transpose(-2, -1)\n",
        "    print(f\"AttentionHead - k_transposed shape: {k_transposed.shape}\")\n",
        "    wei = q @ k_transposed * (self.head_size**-0.5)\n",
        "    print(f\"AttentionHead - wei shape after matmul: {wei.shape}\")\n",
        "\n",
        "\n",
        "    if mask is not None:\n",
        "      local_mask = mask\n",
        "      if local_mask.ndim == 4 and local_mask.shape[1] == 1:\n",
        "          local_mask = local_mask.squeeze(1)\n",
        "      print(f\"AttentionHead - mask shape before masked_fill: {local_mask.shape}\")\n",
        "      wei = wei.masked_fill(local_mask == 0, float('-inf'))\n",
        "      print(f\"AttentionHead - wei shape after masked_fill: {wei.shape}\")\n",
        "\n",
        "\n",
        "    wei = F.softmax(wei, dim=-1) # (B, T_q, T_k)\n",
        "    print(f\"AttentionHead - wei shape after softmax: {wei.shape}\")\n",
        "    wei = self.dropout(wei)\n",
        "    print(f\"AttentionHead - wei shape after dropout: {wei.shape}\")\n",
        "\n",
        "    # attention weights to values\n",
        "    # (B, T_q, T_k) @ (B, T_v, head_size) -> (B, T_q, head_size) (since T_k == T_v)\n",
        "    # torch.bmm for explicit batch matrix multiplication\n",
        "    print(f\"AttentionHead - wei shape before bmm: {wei.shape}\")\n",
        "    print(f\"AttentionHead - v shape before bmm: {v.shape}\")\n",
        "    # Ensure tensors are contiguous before bmm\n",
        "    wei_contiguous = wei.contiguous()\n",
        "    v_contiguous = v.contiguous()\n",
        "    print(f\"AttentionHead - wei_contiguous shape before bmm: {wei_contiguous.shape}\")\n",
        "    print(f\"AttentionHead - v_contiguous shape before bmm: {v_contiguous.shape}\")\n",
        "    out = torch.bmm(wei_contiguous, v_contiguous) # (B, T_q, head_size)\n",
        "    print(f\"AttentionHead - out shape after bmm: {out.shape}\")\n",
        "\n",
        "    return out\n",
        "\n",
        "# multi-head attention, for selfattention with a causal flag\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, n_embed, n_heads, block_size, is_causal):\n",
        "    super().__init__()\n",
        "    self.n_heads = n_heads\n",
        "    self.head_size = n_embed // n_heads\n",
        "\n",
        "    self.heads = nn.ModuleList([\n",
        "        AttentionHead(n_embed, self.head_size) for _ in range(n_heads)\n",
        "    ])\n",
        "    self.proj = nn.Linear(n_heads * self.head_size, n_embed)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    self.is_causal = is_causal\n",
        "\n",
        "    if self.is_causal:\n",
        "      self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "  def forward(self, x, mask=None):\n",
        "    print(f\"MultiHeadAttention - Input x shape: {x.shape}\")\n",
        "    B, T, C = x.shape\n",
        "    local_mask = mask\n",
        "\n",
        "    if self.is_causal:\n",
        "      casual_mask = self.tril[:T, :T].to(x.device)\n",
        "      if local_mask is None:\n",
        "        local_mask = casual_mask\n",
        "      else:\n",
        "        if local_mask.ndim == 3:\n",
        "            local_mask = local_mask.unsqueeze(1)\n",
        "        elif local_mask.ndim == 4:\n",
        "\n",
        "             casual_mask = casual_mask.unsqueeze(1).expand(-1, self.n_heads, -1, -1)\n",
        "\n",
        "        local_mask = local_mask * casual_mask\n",
        "\n",
        "    print(f\"MultiHeadAttention - Mask shape before passing to heads: {local_mask.shape if local_mask is not None else 'None'}\")\n",
        "    out = torch.cat([h(x, x, x, mask=local_mask) for h in self.heads], dim=-1)\n",
        "    print(f\"MultiHeadAttention - out shape after concat: {out.shape}\")\n",
        "\n",
        "\n",
        "    out = self.dropout(self.proj(out))\n",
        "    print(f\"MultiHeadAttention - out shape after proj and dropout: {out.shape}\")\n",
        "    return out\n",
        "\n",
        "# MHCA for encoder-decoder attention\n",
        "class MultiHeadCrossAttention(nn.Module):\n",
        "  def __init__(self, n_heads, n_embed, head_size):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([\n",
        "        AttentionHead(n_embed, head_size) for _ in range(n_heads)\n",
        "    ])\n",
        "    self.proj = nn.Linear(n_heads * head_size, n_embed)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "  def forward(self, query_input, key_value_input, mask=None):\n",
        "    print(f\"MultiHeadCrossAttention - query_input shape: {query_input.shape}\")\n",
        "    print(f\"MultiHeadCrossAttention - key_value_input shape: {key_value_input.shape}\")\n",
        "    local_mask = mask\n",
        "    if local_mask is not None:\n",
        "        # if mask has the correct shape for broadcasting with attention weights (B, H, T_q, T_k)\n",
        "        if local_mask.ndim == 3:\n",
        "            local_mask = local_mask.unsqueeze(1) #reshape to (B, 1, T_q, T_k)\n",
        "\n",
        "    print(f\"MultiHeadCrossAttention - Mask shape before passing to heads: {local_mask.shape if local_mask is not None else 'None'}\")\n",
        "    out = torch.cat([h(query_input, key_value_input, key_value_input, mask=local_mask) for h in self.heads], dim=-1)\n",
        "    print(f\"MultiHeadCrossAttention - out shape after concat: {out.shape}\")\n",
        "\n",
        "\n",
        "    out = self.dropout(self.proj(out))\n",
        "    print(f\"MultiHeadCrossAttention - out shape after proj and dropout: {out.shape}\")\n",
        "    return out\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, n_embed, n_heads, block_size):\n",
        "    super().__init__()\n",
        "    head_size = n_embed // n_heads\n",
        "    self.ln1 = nn.LayerNorm(n_embed)\n",
        "    self.ln2 = nn.LayerNorm(n_embed)\n",
        "    self.ln3 = nn.LayerNorm(n_embed)\n",
        "\n",
        "    self.masked_sa = MultiHeadAttention(n_embed, n_heads, block_size, is_causal=True)\n",
        "    self.cross_sa = MultiHeadCrossAttention(n_heads, n_embed, head_size)\n",
        "    self.ffwd = FeedForward(n_embed)\n",
        "\n",
        "  def forward(self, decoder_input, encoder_output, decoder_padding_mask=None, cross_attention_mask=None):\n",
        "    print(f\"DecoderBlock - decoder_input shape: {decoder_input.shape}\")\n",
        "    print(f\"DecoderBlock - encoder_output shape: {encoder_output.shape}\")\n",
        "    print(f\"DecoderBlock - decoder_padding_mask shape: {decoder_padding_mask.shape if decoder_padding_mask is not None else 'None'}\")\n",
        "    print(f\"DecoderBlock - cross_attention_mask shape: {cross_attention_mask.shape if cross_attention_mask is not None else 'None'}\")\n",
        "\n",
        "    # masked self-attention (uses decoder_padding_mask)\n",
        "    # output is (B, T_dec, C)\n",
        "    ln1_out = self.ln1(decoder_input)\n",
        "    print(f\"DecoderBlock - ln1_out shape before masked_sa: {ln1_out.shape}\")\n",
        "    masked_sa_out = self.masked_sa(ln1_out, mask=decoder_padding_mask)\n",
        "    decoder_output = decoder_input + masked_sa_out\n",
        "    print(f\"DecoderBlock - decoder_output shape after masked_sa: {decoder_output.shape}\")\n",
        "\n",
        "\n",
        "    ln2_out = self.ln2(decoder_output)\n",
        "    print(f\"DecoderBlock - ln2_out shape before cross_sa: {ln2_out.shape}\")\n",
        "    cross_sa_out = self.cross_sa(ln2_out, encoder_output, mask=cross_attention_mask)\n",
        "    decoder_output = decoder_output + cross_sa_out\n",
        "    print(f\"DecoderBlock - decoder_output shape after cross_sa: {decoder_output.shape}\")\n",
        "\n",
        "\n",
        "    # Feed-forward network\n",
        "    ln3_out = self.ln3(decoder_output)\n",
        "    print(f\"DecoderBlock - ln3_out shape before ffwd: {ln3_out.shape}\")\n",
        "    ffwd_out = self.ffwd(ln3_out)\n",
        "    decoder_output = decoder_output + ffwd_out\n",
        "    print(f\"DecoderBlock - decoder_output shape after ffwd: {decoder_output.shape}\")\n",
        "\n",
        "    return decoder_output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dd885ba"
      },
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self, n_embed, n_heads, block_size):\n",
        "    super().__init__()\n",
        "    head_size = n_embed // n_heads\n",
        "    self.ln1 = nn.LayerNorm(n_embed)\n",
        "    self.ln2 = nn.LayerNorm(n_embed)\n",
        "    self.self_attention = MultiHeadAttention(n_embed, n_heads, block_size, is_causal=False) #enc uses non-causal self-attention\n",
        "    self.ffwd = FeedForward(n_embed)\n",
        "\n",
        "  def forward(self, x, padding_mask=None):\n",
        "    x = x + self.self_attention(self.ln1(x), mask=padding_mask)\n",
        "\n",
        "    # Feed-forward network\n",
        "    x = x + self.ffwd(self.ln2(x))\n",
        "    return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EdksRDbMuMA2"
      },
      "outputs": [],
      "source": [
        "#remember dropout for embeddings\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, vocab_size, n_embed, block_size, n_heads, n_layers):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
        "    self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "    self.blocks = nn.Sequential(*[\n",
        "        EncoderBlock(n_embed, n_heads, block_size) for _ in range(n_layers)\n",
        "    ])\n",
        "    self.ln_f = nn.LayerNorm(n_embed)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    self.block_size = block_size\n",
        "\n",
        "  def forward(self, idx, padding_mask=None):\n",
        "    print(f\"Shape at start of Encoder.forward: idx={idx.shape}\")\n",
        "    B, T = idx.shape\n",
        "    tok_emb = self.token_embedding_table(idx)\n",
        "    pos_emb = self.position_embedding_table(torch.arange(T, device=idx.device))\n",
        "    x =self.dropout(tok_emb + pos_emb)\n",
        "    print(f\"Shape after embeddings in Encoder.forward: x={x.shape}\")\n",
        "\n",
        "\n",
        "    for i, block in enumerate(self.blocks):\n",
        "            x = block(x, padding_mask=padding_mask)\n",
        "            print(f\"Shape after EncoderBlock {i}.forward: x={x.shape}\")\n",
        "\n",
        "\n",
        "    x = self.ln_f(x)\n",
        "    print(f\"Shape after LayerNorm in Encoder.forward: x={x.shape}\")\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vcYiGn4Ovn9w"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, vocab_size, n_embed, block_size, n_heads, n_layers):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
        "    self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "    self.blocks = nn.ModuleList([\n",
        "        DecoderBlock(n_embed, n_heads, block_size) for _ in range(n_layers)\n",
        "    ])\n",
        "    self.ln_f = nn.LayerNorm(n_embed)\n",
        "    self.lm_head = nn.Linear(n_embed, vocab_size)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    self.block_size = block_size\n",
        "\n",
        "  def forward(self, decoder_input_ids, encoder_output, decoder_padding_mask=None, cross_attention_mask=None):\n",
        "    B, T = decoder_input_ids.shape\n",
        "    tok_emb = self.token_embedding_table(decoder_input_ids)\n",
        "    pos_emb = self.position_embedding_table(torch.arange(T, device=decoder_input_ids.device))\n",
        "    x = self.dropout(tok_emb + pos_emb)\n",
        "\n",
        "    for block in self.blocks:\n",
        "      #pass decoder_padding_mask and cross_attention_mask with correct keyword arguments\n",
        "      x = block(x, encoder_output, decoder_padding_mask=decoder_padding_mask, cross_attention_mask=cross_attention_mask)\n",
        "\n",
        "    x = self.ln_f(x)\n",
        "    logits = self.lm_head(x)\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "faTCsC_6xu2r"
      },
      "outputs": [],
      "source": [
        "class EncoderDecoderTransformer(nn.Module):\n",
        "  def __init__(self, vocab_size, n_embed, block_size, n_heads, n_layers):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(vocab_size, n_embed, block_size, n_heads, n_layers)\n",
        "    self.decoder = Decoder(vocab_size, n_embed, block_size, n_heads, n_layers)\n",
        "\n",
        "  def forward(self, encoder_input_ids, decoder_input_ids, targets=None,\n",
        "              encoder_padding_mask=None, decoder_padding_mask=None, cross_attention_mask=None):\n",
        "      print(f\"Shape at start of EncoderDecoderTransformer.forward: encoder_input_ids={encoder_input_ids.shape}, decoder_input_ids={decoder_input_ids.shape}\")\n",
        "      encoder_output = self.encoder(encoder_input_ids, padding_mask=encoder_padding_mask)\n",
        "      print(f\"Shape after Encoder.forward: encoder_output={encoder_output.shape}\")\n",
        "      logits = self.decoder(decoder_input_ids, encoder_output, decoder_padding_mask=decoder_padding_mask, cross_attention_mask=cross_attention_mask)\n",
        "      print(f\"Shape after Decoder.forward: logits={logits.shape}\")\n",
        "\n",
        "\n",
        "      loss = None\n",
        "      if targets is not None:\n",
        "        print(f\"Shape of logits just before unpacking in EncoderDecoderTransformer.forward (for loss calc): {logits.shape}\")\n",
        "        B, T, C = logits.shape\n",
        "        logits_reshaped = logits.view(B*T, C)\n",
        "        targets_reshaped = targets.view(B*T)\n",
        "\n",
        "        # target values that are EOS_TOKEN_ID to PAD_TOKEN_ID so they are ignored\n",
        "        targets_reshaped[targets_reshaped == EOS_TOKEN_ID] = PAD_TOKEN_ID\n",
        "\n",
        "        loss = F.cross_entropy(logits_reshaped, targets_reshaped, ignore_index = PAD_TOKEN_ID)\n",
        "\n",
        "      return logits, loss\n",
        "\n",
        "  def generate(self, encoder_input_ids, max_new_tokens, encoder_padding_mask=None):\n",
        "    encoder_output = self.encoder(encoder_input_ids, padding_mask=encoder_padding_mask)\n",
        "    # batch size\n",
        "    B = encoder_input_ids.shape[0]\n",
        "    decoder_input_ids = torch.full((B, 1), SOS_TOKEN_ID, dtype=torch.long, device=encoder_input_ids.device)\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "      decoder_input_cond = decoder_input_ids[:, -self.decoder.block_size:]\n",
        "\n",
        "      _, T_enc, _ = encoder_output.shape\n",
        "      _, T_dec_cond = decoder_input_cond.shape\n",
        "      cross_attention_mask = torch.ones(B, T_dec_cond, T_enc, dtype=torch.bool, device=encoder_input_ids.device)\n",
        "\n",
        "\n",
        "      logits = self.decoder(decoder_input_cond, encoder_output, cross_attention_mask=cross_attention_mask)\n",
        "      logits = logits[:, -1, :]\n",
        "\n",
        "      probs = F.softmax(logits, dim=-1)\n",
        "      next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "      decoder_input_ids = torch.cat((decoder_input_ids, next_token), dim=1)\n",
        "\n",
        "      if (next_token == EOS_TOKEN_ID).all():\n",
        "          break\n",
        "    return decoder_input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-fskdg3I4J9K"
      },
      "outputs": [],
      "source": [
        "def get_batch_seq2seq(split, direction='json_to_str'):\n",
        "  if direction == 'json_to_str':\n",
        "      data_source = train_json_to_str if split == 'train' else val_json_to_str\n",
        "  else:\n",
        "      data_source = train_str_to_json if split == 'train' else val_str_to_json\n",
        "\n",
        "  batch_enc_in, batch_dec_in, batch_dec_tgt = [], [], []\n",
        "  indices = torch.randint(0, len(data_source), (batch_size,))\n",
        "\n",
        "  for i in indices:\n",
        "    enc_ids, dec_in_ids, dec_tgt_ids = data_source[i.item()]\n",
        "    batch_enc_in.append(torch.tensor(enc_ids, dtype=torch.long))\n",
        "    batch_dec_in.append(torch.tensor(dec_in_ids, dtype=torch.long))\n",
        "    batch_dec_tgt.append(torch.tensor(dec_tgt_ids, dtype=torch.long))\n",
        "\n",
        "  # Use pad_sequence for efficient padding\n",
        "  padded_enc_inputs = nn.utils.rnn.pad_sequence(batch_enc_in, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
        "  padded_dec_inputs = nn.utils.rnn.pad_sequence(batch_dec_in, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
        "  padded_dec_targets = nn.utils.rnn.pad_sequence(batch_dec_tgt, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
        "\n",
        "  #masks , 1 for real token , 0 for padding\n",
        "  # (B, T_enc) -> (B, 1, T_enc) -> (B, T_enc, T_enc)\n",
        "  encoder_padding_mask = (padded_enc_inputs != PAD_TOKEN_ID).unsqueeze(1)\n",
        "  encoder_padding_mask = encoder_padding_mask * encoder_padding_mask.transpose(-2, -1)\n",
        "\n",
        "  # (B, T_dec) -> (B, 1, T_dec) -> (B, T_dec, T_dec)\n",
        "  decoder_padding_mask = (padded_dec_inputs != PAD_TOKEN_ID).unsqueeze(1)\n",
        "  decoder_padding_mask = decoder_padding_mask * decoder_padding_mask.transpose(-2, -1)\n",
        "\n",
        "  cross_attention_mask = (padded_dec_inputs != PAD_TOKEN_ID).unsqueeze(-1) * \\\n",
        "                         (padded_enc_inputs != PAD_TOKEN_ID).unsqueeze(1)\n",
        "\n",
        "  print(f\"get_batch_seq2seq - padded_enc_inputs shape: {padded_enc_inputs.shape}\")\n",
        "  print(f\"get_batch_seq2seq - padded_dec_inputs shape: {padded_dec_inputs.shape}\")\n",
        "  print(f\"get_batch_seq2seq - padded_dec_targets shape: {padded_dec_targets.shape}\")\n",
        "  print(f\"get_batch_seq2seq - encoder_padding_mask shape: {encoder_padding_mask.shape}\")\n",
        "  print(f\"get_batch_seq2seq - decoder_padding_mask shape: {decoder_padding_mask.shape}\")\n",
        "  print(f\"get_batch_seq2seq - cross_attention_mask shape: {cross_attention_mask.shape}\")\n",
        "\n",
        "\n",
        "  return padded_enc_inputs.to(device), padded_dec_inputs.to(device), padded_dec_targets.to(device), \\\n",
        "         encoder_padding_mask.to(device), decoder_padding_mask.to(device), cross_attention_mask.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiRlrT0l6RuP",
        "outputId": "d592d17c-6961-4a74-efb3-30eaa3e6d770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 17])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 17])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 17])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 17])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 17])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 17])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 26, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 17, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 26, 26])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 26, 17])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 26])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 17, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 17])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 17])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 17])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 17])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 17])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 17])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 17])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 17])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 17])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 26, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 17, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 26, 26])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 26, 17])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 26])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 17, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 17])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 17])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 17])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 17])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 17])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 17])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 17])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 17, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 17, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 17])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 17])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 17])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 17])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 17, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 26, 256])\n",
            "Shape after Decoder.forward: logits=torch.Size([32, 26, 100000])\n",
            "Shape of logits just before unpacking in EncoderDecoderTransformer.forward (for loss calc): torch.Size([32, 26, 100000])\n",
            "get_batch_seq2seq - padded_enc_inputs shape: torch.Size([32, 25])\n",
            "get_batch_seq2seq - padded_dec_inputs shape: torch.Size([32, 19])\n",
            "get_batch_seq2seq - padded_dec_targets shape: torch.Size([32, 19])\n",
            "get_batch_seq2seq - encoder_padding_mask shape: torch.Size([32, 25, 25])\n",
            "get_batch_seq2seq - decoder_padding_mask shape: torch.Size([32, 19, 19])\n",
            "get_batch_seq2seq - cross_attention_mask shape: torch.Size([32, 19, 25])\n",
            "Shape at start of EncoderDecoderTransformer.forward: encoder_input_ids=torch.Size([32, 25]), decoder_input_ids=torch.Size([32, 19])\n",
            "Shape at start of Encoder.forward: idx=torch.Size([32, 25])\n",
            "Shape after embeddings in Encoder.forward: x=torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 25, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 25, 256])\n",
            "Shape after EncoderBlock 0.forward: x=torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 25, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 25, 256])\n",
            "Shape after EncoderBlock 1.forward: x=torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 25, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 25, 256])\n",
            "Shape after EncoderBlock 2.forward: x=torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 25, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 25, 256])\n",
            "Shape after EncoderBlock 3.forward: x=torch.Size([32, 25, 256])\n",
            "Shape after LayerNorm in Encoder.forward: x=torch.Size([32, 25, 256])\n",
            "Shape after Encoder.forward: encoder_output=torch.Size([32, 25, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 19, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 25, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 19, 19])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 19, 25])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 19, 19])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 19, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 25, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 19, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 19, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 19, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 25, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 19, 19])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 19, 25])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 19, 19])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 19, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 25, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 19, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 19, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 19, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 25, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 19, 19])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 19, 25])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 19, 19])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 19, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 25, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 19, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 19, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 19, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 25, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 19, 19])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 19, 25])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 19, 19])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 19, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 25, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 19, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 19, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 19, 256])\n",
            "Shape after Decoder.forward: logits=torch.Size([32, 19, 100000])\n",
            "Shape of logits just before unpacking in EncoderDecoderTransformer.forward (for loss calc): torch.Size([32, 19, 100000])\n",
            "get_batch_seq2seq - padded_enc_inputs shape: torch.Size([32, 18])\n",
            "get_batch_seq2seq - padded_dec_inputs shape: torch.Size([32, 26])\n",
            "get_batch_seq2seq - padded_dec_targets shape: torch.Size([32, 26])\n",
            "get_batch_seq2seq - encoder_padding_mask shape: torch.Size([32, 18, 18])\n",
            "get_batch_seq2seq - decoder_padding_mask shape: torch.Size([32, 26, 26])\n",
            "get_batch_seq2seq - cross_attention_mask shape: torch.Size([32, 26, 18])\n",
            "Shape at start of EncoderDecoderTransformer.forward: encoder_input_ids=torch.Size([32, 18]), decoder_input_ids=torch.Size([32, 26])\n",
            "Shape at start of Encoder.forward: idx=torch.Size([32, 18])\n",
            "Shape after embeddings in Encoder.forward: x=torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 18, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 18, 256])\n",
            "Shape after EncoderBlock 0.forward: x=torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 18, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 18, 256])\n",
            "Shape after EncoderBlock 1.forward: x=torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 18, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 18, 256])\n",
            "Shape after EncoderBlock 2.forward: x=torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 18, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 18, 256])\n",
            "Shape after EncoderBlock 3.forward: x=torch.Size([32, 18, 256])\n",
            "Shape after LayerNorm in Encoder.forward: x=torch.Size([32, 18, 256])\n",
            "Shape after Encoder.forward: encoder_output=torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 26, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 26, 26])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 26, 18])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 26])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 26, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 26, 26])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 26, 18])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 26])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 26, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 26, 26])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 26, 18])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 26])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 26, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 26, 26])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 26, 18])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 26])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 26, 256])\n",
            "Shape after Decoder.forward: logits=torch.Size([32, 26, 100000])\n",
            "Shape of logits just before unpacking in EncoderDecoderTransformer.forward (for loss calc): torch.Size([32, 26, 100000])\n",
            "get_batch_seq2seq - padded_enc_inputs shape: torch.Size([32, 25])\n",
            "get_batch_seq2seq - padded_dec_inputs shape: torch.Size([32, 19])\n",
            "get_batch_seq2seq - padded_dec_targets shape: torch.Size([32, 19])\n",
            "get_batch_seq2seq - encoder_padding_mask shape: torch.Size([32, 25, 25])\n",
            "get_batch_seq2seq - decoder_padding_mask shape: torch.Size([32, 19, 19])\n",
            "get_batch_seq2seq - cross_attention_mask shape: torch.Size([32, 19, 25])\n",
            "Shape at start of EncoderDecoderTransformer.forward: encoder_input_ids=torch.Size([32, 25]), decoder_input_ids=torch.Size([32, 19])\n",
            "Shape at start of Encoder.forward: idx=torch.Size([32, 25])\n",
            "Shape after embeddings in Encoder.forward: x=torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 25, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 25, 256])\n",
            "Shape after EncoderBlock 0.forward: x=torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 25, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 25, 256])\n",
            "Shape after EncoderBlock 1.forward: x=torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 25, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 25, 256])\n",
            "Shape after EncoderBlock 2.forward: x=torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 25, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 25, 256])\n",
            "Shape after EncoderBlock 3.forward: x=torch.Size([32, 25, 256])\n",
            "Shape after LayerNorm in Encoder.forward: x=torch.Size([32, 25, 256])\n",
            "Shape after Encoder.forward: encoder_output=torch.Size([32, 25, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 19, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 25, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 19, 19])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 19, 25])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 19, 19])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 19, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 25, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 19, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 19, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 19, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 25, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 19, 19])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 19, 25])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 19, 19])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 19, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 25, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 19, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 19, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 19, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 25, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 19, 19])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 19, 25])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 19, 19])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 19, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 25, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 19, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 19, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 19, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 25, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 19, 19])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 19, 25])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 19, 19])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 19])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 19])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 19])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 19])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 19, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 19, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 25, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 19, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 19, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 19, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 19, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 19, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 19, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 19, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 19, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 19, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 19, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 19, 256])\n",
            "Shape after Decoder.forward: logits=torch.Size([32, 19, 100000])\n",
            "Shape of logits just before unpacking in EncoderDecoderTransformer.forward (for loss calc): torch.Size([32, 19, 100000])\n",
            "get_batch_seq2seq - padded_enc_inputs shape: torch.Size([32, 18])\n",
            "get_batch_seq2seq - padded_dec_inputs shape: torch.Size([32, 26])\n",
            "get_batch_seq2seq - padded_dec_targets shape: torch.Size([32, 26])\n",
            "get_batch_seq2seq - encoder_padding_mask shape: torch.Size([32, 18, 18])\n",
            "get_batch_seq2seq - decoder_padding_mask shape: torch.Size([32, 26, 26])\n",
            "get_batch_seq2seq - cross_attention_mask shape: torch.Size([32, 26, 18])\n",
            "Shape at start of EncoderDecoderTransformer.forward: encoder_input_ids=torch.Size([32, 18]), decoder_input_ids=torch.Size([32, 26])\n",
            "Shape at start of Encoder.forward: idx=torch.Size([32, 18])\n",
            "Shape after embeddings in Encoder.forward: x=torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 18, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 18, 256])\n",
            "Shape after EncoderBlock 0.forward: x=torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 18, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 18, 256])\n",
            "Shape after EncoderBlock 1.forward: x=torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 18, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 18, 256])\n",
            "Shape after EncoderBlock 2.forward: x=torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 18, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 18, 256])\n",
            "Shape after EncoderBlock 3.forward: x=torch.Size([32, 18, 256])\n",
            "Shape after LayerNorm in Encoder.forward: x=torch.Size([32, 18, 256])\n",
            "Shape after Encoder.forward: encoder_output=torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 26, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 26, 26])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 26, 18])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 26])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 26, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 26, 26])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 26, 18])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 26])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 26, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 26, 26])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 26, 18])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 26])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 26, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 26, 26])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 26, 18])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 26])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 26])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 26])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 26])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 26])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 26, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 26, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 26, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 26, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 26, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 26, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 26, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 26, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 26, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 26, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 26, 256])\n",
            "Shape after Decoder.forward: logits=torch.Size([32, 26, 100000])\n",
            "Shape of logits just before unpacking in EncoderDecoderTransformer.forward (for loss calc): torch.Size([32, 26, 100000])\n",
            "get_batch_seq2seq - padded_enc_inputs shape: torch.Size([32, 25])\n",
            "get_batch_seq2seq - padded_dec_inputs shape: torch.Size([32, 18])\n",
            "get_batch_seq2seq - padded_dec_targets shape: torch.Size([32, 18])\n",
            "get_batch_seq2seq - encoder_padding_mask shape: torch.Size([32, 25, 25])\n",
            "get_batch_seq2seq - decoder_padding_mask shape: torch.Size([32, 18, 18])\n",
            "get_batch_seq2seq - cross_attention_mask shape: torch.Size([32, 18, 25])\n",
            "Shape at start of EncoderDecoderTransformer.forward: encoder_input_ids=torch.Size([32, 25]), decoder_input_ids=torch.Size([32, 18])\n",
            "Shape at start of Encoder.forward: idx=torch.Size([32, 25])\n",
            "Shape after embeddings in Encoder.forward: x=torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 25, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 25, 256])\n",
            "Shape after EncoderBlock 0.forward: x=torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 25, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 25, 256])\n",
            "Shape after EncoderBlock 1.forward: x=torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 25, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 25, 256])\n",
            "Shape after EncoderBlock 2.forward: x=torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 25, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 25, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 25, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 25, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 25, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 25, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 25, 256])\n",
            "Shape after EncoderBlock 3.forward: x=torch.Size([32, 25, 256])\n",
            "Shape after LayerNorm in Encoder.forward: x=torch.Size([32, 25, 256])\n",
            "Shape after Encoder.forward: encoder_output=torch.Size([32, 25, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 18, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 25, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 18, 18])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 18, 25])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 18, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 18, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 25, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 18, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 18, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 18, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 25, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 18, 18])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 18, 25])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 18, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 18, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 25, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 18, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 18, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 18, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 25, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 18, 18])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 18, 25])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 18, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 18, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 25, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 18, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 18, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_input shape: torch.Size([32, 18, 256])\n",
            "DecoderBlock - encoder_output shape: torch.Size([32, 25, 256])\n",
            "DecoderBlock - decoder_padding_mask shape: torch.Size([32, 18, 18])\n",
            "DecoderBlock - cross_attention_mask shape: torch.Size([32, 18, 25])\n",
            "DecoderBlock - ln1_out shape before masked_sa: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Input x shape: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - Mask shape before passing to heads: torch.Size([32, 1, 18, 18])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 18])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 18])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 18])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 18])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "MultiHeadAttention - out shape after concat: torch.Size([32, 18, 256])\n",
            "MultiHeadAttention - out shape after proj and dropout: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_output shape after masked_sa: torch.Size([32, 18, 256])\n",
            "DecoderBlock - ln2_out shape before cross_sa: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - query_input shape: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - key_value_input shape: torch.Size([32, 25, 256])\n",
            "MultiHeadCrossAttention - Mask shape before passing to heads: torch.Size([32, 1, 18, 25])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "AttentionHead - query_input shape: torch.Size([32, 18, 256])\n",
            "AttentionHead - key_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - value_input shape: torch.Size([32, 25, 256])\n",
            "AttentionHead - q shape: torch.Size([32, 18, 64])\n",
            "AttentionHead - k shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - v shape: torch.Size([32, 25, 64])\n",
            "AttentionHead - k_transposed shape: torch.Size([32, 64, 25])\n",
            "AttentionHead - wei shape after matmul: torch.Size([32, 18, 25])\n",
            "AttentionHead - mask shape before masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after masked_fill: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after softmax: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape after dropout: torch.Size([32, 18, 25])\n",
            "AttentionHead - wei shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - wei_contiguous shape before bmm: torch.Size([32, 18, 25])\n",
            "AttentionHead - v_contiguous shape before bmm: torch.Size([32, 25, 64])\n",
            "AttentionHead - out shape after bmm: torch.Size([32, 18, 64])\n",
            "MultiHeadCrossAttention - out shape after concat: torch.Size([32, 18, 256])\n",
            "MultiHeadCrossAttention - out shape after proj and dropout: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_output shape after cross_sa: torch.Size([32, 18, 256])\n",
            "DecoderBlock - ln3_out shape before ffwd: torch.Size([32, 18, 256])\n",
            "DecoderBlock - decoder_output shape after ffwd: torch.Size([32, 18, 256])\n",
            "Shape after Decoder.forward: logits=torch.Size([32, 18, 100000])\n",
            "Shape of logits just before unpacking in EncoderDecoderTransformer.forward (for loss calc): torch.Size([32, 18, 100000])\n",
            "get_batch_seq2seq - padded_enc_inputs shape: torch.Size([32, 18])\n",
            "get_batch_seq2seq - padded_dec_inputs shape: torch.Size([32, 26])\n",
            "get_batch_seq2seq - padded_dec_targets shape: torch.Size([32, 26])\n",
            "get_batch_seq2seq - encoder_padding_mask shape: torch.Size([32, 18, 18])\n",
            "get_batch_seq2seq - decoder_padding_mask shape: torch.Size([32, 26, 26])\n",
            "get_batch_seq2seq - cross_attention_mask shape: torch.Size([32, 26, 18])\n"
          ]
        }
      ],
      "source": [
        "#two models one for each direction\n",
        "\n",
        "model_json_to_str = EncoderDecoderTransformer(\n",
        "    vocab_size=vocab_size, n_embed=n_embed, n_heads=n_heads, n_layers=n_layers, block_size=block_size\n",
        ").to(device)\n",
        "optimiser_json_to_str = optim.AdamW(model_json_to_str.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "model_str_to_json = EncoderDecoderTransformer(\n",
        "    vocab_size=vocab_size, n_embed=n_embed, n_heads=n_heads, n_layers=n_layers, block_size=block_size\n",
        ").to(device)\n",
        "optimiser_str_to_json = optim.AdamW(model_str_to_json.parameters(), lr=learning_rate)\n",
        "\n",
        "#track best val loss for both\n",
        "best_val_loss_j2s = float('inf')\n",
        "best_val_loss_s2j = float('inf')\n",
        "\n",
        "for step in range(max_iters):\n",
        "  #training j2s\n",
        "  model_json_to_str.train()\n",
        "  enc_in_j2s, dec_in_j2s, dec_tgt_j2s, enc_mask_j2s, dec_mask_j2s, cross_mask_j2s = \\\n",
        "    get_batch_seq2seq('train', direction='json_to_str')\n",
        "\n",
        "  logits_j2s, loss_j2s = model_json_to_str(enc_in_j2s, dec_in_j2s, dec_tgt_j2s, enc_mask_j2s, dec_mask_j2s, cross_mask_j2s)\n",
        "  optimiser_json_to_str.zero_grad()\n",
        "  loss_j2s.backward()\n",
        "  optimiser_json_to_str.step()\n",
        "\n",
        "  #training s2j\n",
        "  model_str_to_json.train()\n",
        "  enc_in_s2j, dec_in_s2j, dec_tgt_s2j, enc_mask_s2j, dec_mask_s2j, cross_mask_s2j = \\\n",
        "    get_batch_seq2seq('train', direction='str_to_json')\n",
        "\n",
        "  logits_s2j, loss_s2j = model_str_to_json(enc_in_s2j, dec_in_s2j, dec_tgt_s2j, enc_mask_s2j, dec_mask_s2j, cross_mask_s2j)\n",
        "  optimiser_str_to_json.zero_grad()\n",
        "  loss_s2j.backward()\n",
        "  optimiser_str_to_json.step()\n",
        "\n",
        "  #evaluate and save checkpoints\n",
        "  if step % eval_interval == 0:\n",
        "    model_json_to_str.eval()\n",
        "    model_str_to_json.eval()\n",
        "    with torch.no_grad():\n",
        "      #j2s validation\n",
        "      val_enc_in_j2s, val_dec_in_j2s, val_dec_tgt_j2s, val_enc_mask_j2s, val_dec_mask_j2s, val_cross_mask_j2s = \\\n",
        "        get_batch_seq2seq('val', direction='json_to_str')\n",
        "\n",
        "      _, val_loss_j2s = model_json_to_str(val_enc_in_j2s, val_dec_in_j2s, val_dec_tgt_j2s, val_enc_mask_j2s, val_dec_mask_j2s, val_cross_mask_j2s)\n",
        "\n",
        "      #s2j validation\n",
        "      val_enc_in_s2j, val_dec_in_s2j, val_dec_tgt_s2j, val_enc_mask_s2j, val_dec_mask_s2j, val_cross_mask_s2j = \\\n",
        "        get_batch_seq2seq('val', direction=\"str_to_json\")\n",
        "\n",
        "      _, val_loss_s2j = model_str_to_json(val_enc_in_s2j, val_dec_in_s2j, val_dec_tgt_s2j, val_enc_mask_s2j, val_dec_mask_s2j, val_cross_mask_s2j)\n",
        "\n",
        "      print(f\"[step {step}] J2S train loss: {loss_j2s.item():.4f} | J2S val loss: {val_loss_j2s.item():.4f}\")\n",
        "      print(f\"[step {step}] S2J train loss: {loss_s2j.item():.4f} | S2J val loss: {val_loss_s2j.item():.4f}\")\n",
        "\n",
        "      #save checkpoints\n",
        "      if val_loss_j2s.item() < best_val_loss_j2s:\n",
        "        best_val_loss_j2s = val_loss_j2s.item()\n",
        "        torch.save(model_json_to_str.state_dict(), 'best_model_json_to_str.pt')\n",
        "        print(\"~~~~ Saved best J2S model ~~~~\")\n",
        "\n",
        "      elif step == 0:\n",
        "          torch.save(model_json_to_str.state_dict(), 'best_model_json_to_str.pt')\n",
        "          print(\"~~~~ Saved initial J2S model at step 0 ~~~~\")\n",
        "\n",
        "\n",
        "      if val_loss_s2j.item() < best_val_loss_s2j:\n",
        "        best_val_loss_s2j = val_loss_s2j.item()\n",
        "        torch.save(model_str_to_json.state_dict(), 'best_model_str_to_json.pt')\n",
        "        print(\"~~~~ Saved best S2J model ~~~~\")\n",
        "\n",
        "      elif step == 0:\n",
        "          torch.save(model_str_to_json.state_dict(), 'best_model_str_to_json.pt')\n",
        "          print(\"~~~~ Saved initial S2J model at step 0 ~~~~\")\n",
        "\n",
        "\n",
        "print(\"~~~~ TRAINING COMPLETE ~~~~\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ab32089",
        "outputId": "03222c5f-f658-4c7d-a6b5-b303bc5eac60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing MultiHeadAttention with is_causal=False\n",
            "MultiHeadAttention (is_causal=False) output shape: torch.Size([32, 32, 32, 256])\n",
            "\n",
            "Testing MultiHeadAttention with is_causal=True\n",
            "MultiHeadAttention (is_causal=True) output shape: torch.Size([32, 32, 32, 256])\n",
            "\n",
            "Testing AttentionHead in isolation\n",
            "AttentionHead output shape: torch.Size([32, 32, 32, 64])\n"
          ]
        }
      ],
      "source": [
        "# solated test for MultiHeadAttention\n",
        "B, T, C = batch_size, block_size, n_embed\n",
        "dummy_input = torch.randn(B, T, C, device=device)\n",
        "dummy_mask = torch.ones(B, T, T, dtype=torch.bool, device=device)\n",
        "\n",
        "try:\n",
        "    print(\"Testing MultiHeadAttention with is_causal=False\")\n",
        "    mha_test_causal_false = MultiHeadAttention(n_embed, n_heads, block_size, is_causal=False).to(device)\n",
        "    output_causal_false = mha_test_causal_false(dummy_input, mask=dummy_mask)\n",
        "    print(f\"MultiHeadAttention (is_causal=False) output shape: {output_causal_false.shape}\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error during MultiHeadAttention (is_causal=False) test: {e}\")\n",
        "\n",
        "try:\n",
        "    print(\"\\nTesting MultiHeadAttention with is_causal=True\")\n",
        "    mha_test_causal_true = MultiHeadAttention(n_embed, n_heads, block_size, is_causal=True).to(device)\n",
        "    output_causal_true = mha_test_causal_true(dummy_input, mask=dummy_mask)\n",
        "    print(f\"MultiHeadAttention (is_causal=True) output shape: {output_causal_true.shape}\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error during MultiHeadAttention (is_causal=True) test: {e}\")\n",
        "\n",
        "try:\n",
        "    print(\"\\nTesting AttentionHead in isolation\")\n",
        "    head_test = AttentionHead(n_embed, n_embed // n_heads).to(device)\n",
        "    output_head_test = head_test(dummy_input, dummy_input, dummy_input, mask=dummy_mask)\n",
        "    print(f\"AttentionHead output shape: {output_head_test.shape}\")\n",
        "except ValueError as e:\n",
        "     print(f\"Error during AttentionHead test: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EgEfifqlPTIR"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNOuXPw7+DL3xRn0HOhRI6e"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}